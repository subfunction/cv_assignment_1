{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6078ba81",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.py\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, nChannel=1):\n",
    "        super(SRCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(nChannel, 64,\n",
    "            kernel_size=9, padding=9//2)\n",
    "        self.conv2 = nn.Conv2d(64, 32,\n",
    "            kernel_size=5, padding=5//2)\n",
    "        self.conv3 = nn.Conv2d(32, nChannel, \n",
    "            kernel_size=5, padding=5//2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55110af5",
   "metadata": {},
   "source": [
    "数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import PIL.Image as pImg\n",
    "\n",
    "def rgb2gray(img):\n",
    "    return 16. + (64.738 * img[:, :, 0] + 129.057 * img[:, :, 1] + 25.064 * img[:, :, 2]) / 256.\n",
    "\n",
    "# imgPath为图像路径；h5Path为存储路径；scale为放大倍数\n",
    "# pSize为patch尺寸； pStride为步长\n",
    "def setTrianData(imgPath, h5Path, scale=3, pSize=33, pStride=14):\n",
    "    h5_file = h5py.File(h5Path, 'w')\n",
    "    lrPatches, hrPatches = [], []       #用于存储低分辨率和高分辨率的patch\n",
    "    for p in sorted(glob.glob(f'{imgPath}/*')):\n",
    "        hr = pImg.open(p).convert('RGB')\n",
    "        lrWidth, lrHeight = hr.width // scale, hr.height // scale\n",
    "        # width, height为可被scale整除的训练数据尺寸\n",
    "        width, height = lrWidth*scale, lrHeight*scale\n",
    "        hr = hr.resize((width, height), resample=pImg.BICUBIC)\n",
    "        lr = hr.resize((lrWidth, lrHeight), resample=pImg.BICUBIC)\n",
    "        lr = lr.resize((width, height), resample=pImg.BICUBIC)\n",
    "        hr = np.array(hr).astype(np.float32)\n",
    "        lr = np.array(lr).astype(np.float32)\n",
    "        hr = rgb2gray(hr)\n",
    "        lr = rgb2gray(lr)\n",
    "        # 将数据分割\n",
    "        for i in range(0, height - pSize + 1, pStride):\n",
    "            for j in range(0, width - pSize + 1, pStride):\n",
    "                lrPatches.append(lr[i:i + pSize, j:j + pSize])\n",
    "                hrPatches.append(hr[i:i + pSize, j:j + pSize])\n",
    "    h5_file.create_dataset('lr', data=np.array(lrPatches))\n",
    "    h5_file.create_dataset('hr', data=np.array(hrPatches))\n",
    "    h5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6735d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DataSet(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.h5_file = h5_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return np.expand_dims(f['lr'][idx] / 255., 0), np.expand_dims(f['hr'][idx] / 255., 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return len(f['lr'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ddb7f",
   "metadata": {},
   "source": [
    "数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38699165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from models import SRCNN\n",
    "\n",
    "trainFile = \"91-image.h5\"\n",
    "evalFile = \"Set5.h5\"\n",
    "\n",
    "cudnn.benchmark = True\n",
    "# 设置训练设备 是CPU还是cuda\n",
    "device = torch.device(\n",
    "  'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 装载训练数据\n",
    "trainData = Dataset(trainFile)\n",
    "trainLoader = DataLoader(dataset=trainData,\n",
    "  bSize=bSize,\n",
    "  shuffle=True,               # 表示打乱样本\n",
    "  num_workers=nWorker,        # 线程数\n",
    "  pin_memory=True,            # 方便载入CUDA\n",
    "  drop_last=True)\n",
    "\n",
    "# 装载预测数据\n",
    "evalDatas = Dataset(evalFile)\n",
    "evalLoader = DataLoader(dataset=evalDatas, bSize=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c8269",
   "metadata": {},
   "source": [
    "模型准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型和设备\n",
    "lr = 1e-4       #学习率\n",
    "torch.manual_seed(seed)     #设置随机数种子\n",
    "model = SRCNN().to(device)  #将模型载入设备\n",
    "criterion = nn.MSELoss()    #设置损失函数\n",
    "optimizer = optim.Adam([\n",
    "  {'params': model.conv1.parameters()},\n",
    "  {'params': model.conv2.parameters()},\n",
    "  {'params': model.conv3.parameters(), 'lr': lr * 0.1}\n",
    "], lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce063a",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008cabfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outPath = \"outputs\"\n",
    "scale = 3\n",
    "bSize = 16\n",
    "nEpoch = 400\n",
    "nWorker = 8     #线程数\n",
    "seed = 42       #随机数种子\n",
    "\n",
    "def initPSNR():\n",
    "    return {'avg':0, 'sum':0, 'count':0}\n",
    "\n",
    "def updatePSNR(psnr, val, n=1):\n",
    "    s = psnr['sum'] + val*n\n",
    "    c = psnr['count'] + n\n",
    "    return {'avg':s/c, 'sum':s, 'count':c}\n",
    "\n",
    "bestWeights = copy.deepcopy(model.state_dict()) #最佳模型\n",
    "bestEpoch = 0   #最佳训练结果\n",
    "bestPSNR = 0.0  #最佳psnr\n",
    "\n",
    "# 训练主循环\n",
    "for epoch in range(nEpoch):\n",
    "  model.train()\n",
    "  epochLosses = initPSNR()\n",
    "\n",
    "  for data in trainLoader:\n",
    "      inputs, labels = data\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "      preds = model(inputs)\n",
    "      loss = criterion(preds, labels)\n",
    "      epochLosses = updatePSNR(epochLosses,loss.item(), len(inputs))\n",
    "      optimizer.zero_grad()   #清空梯度\n",
    "      loss.backward()         #反向传播\n",
    "      optimizer.step()        #根据梯度更新网络参数\n",
    "      print(f'{epochLosses['avg']:.6f}')\n",
    "\n",
    "  torch.save(model.state_dict(), \n",
    "      os.path.join(outPath, f'epoch_{epoch}.pth'))\n",
    "\n",
    "  model.eval()    #取消dropout\n",
    "  psnr = AverageMeter()\n",
    "\n",
    "  for data in evalLoader:\n",
    "      inputs, labels = data\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "      # 令reqires_grad自动设为False，关闭自动求导\n",
    "      # clamp将inputs归一化为0到1区间\n",
    "      with torch.no_grad():\n",
    "          preds = model(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "      tmp_psnr = 10. * torch.log10(\n",
    "          1. / torch.mean((preds - labels) ** 2))\n",
    "      psnr = updatePSNR(psnr, tmp_psnr, len(inputs))\n",
    "\n",
    "  print(f'eval psnr: {psnr.avg:.2f}')\n",
    "\n",
    "  if psnr['avg'] > bestPSNR:\n",
    "      bestEpoch = epoch\n",
    "      bestPSNR = psnr['avg']\n",
    "      bestWeights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "print(f'best epoch: {bestEpoch}, psnr: {bestPSNR:.2f}')\n",
    "torch.save(bestWeights, os.path.join(outPath, 'best.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
