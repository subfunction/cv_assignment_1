{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d85ca0",
   "metadata": {},
   "source": [
    "损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555470cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, input_channel=64, output_channel=64, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, output_channel, kernel_size, stride, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(output_channel),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            nn.Conv2d(output_channel, output_channel, kernel_size, stride, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(output_channel)\n",
    "        )\n",
    "\n",
    "    def forward(self, x0):\n",
    "        x1 = self.layer(x0)\n",
    "        return x0 + x1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(VGG, self).__init__()\n",
    "        vgg = models.vgg19(True)\n",
    "        for pa in vgg.parameters():\n",
    "            pa.requires_grad = False\n",
    "        self.vgg = vgg.features[:16]\n",
    "        self.vgg = self.vgg.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.vgg(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.vgg19 = VGG(device)\n",
    "\n",
    "    def forward(self, fake, real):\n",
    "        feature_fake = self.vgg19(fake)\n",
    "        feature_real = self.vgg19(real)\n",
    "        loss = self.mse(feature_fake, feature_real)\n",
    "        return loss\n",
    "\n",
    "    class AdversarialLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        loss = torch.sum(-torch.log(x))\n",
    "        return loss\n",
    "    \n",
    "    class PerceptualLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.vgg_loss = ContentLoss(device)\n",
    "        self.adversarial = AdversarialLoss()\n",
    "\n",
    "    def forward(self, fake, real, x):\n",
    "        vgg_loss = self.vgg_loss(fake, real)\n",
    "        adversarial_loss = self.adversarial(x)\n",
    "        return vgg_loss + 1e-3*adversarial_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf059e3",
   "metadata": {},
   "source": [
    "正则项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17696d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizationLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = torch.square(\n",
    "            x[:, :, :x.shape[2]-1, :x.shape[3]-1] - x[:, :, 1:x.shape[2], :x.shape[3]-1]\n",
    "        )\n",
    "        b = torch.square(\n",
    "            x[:, :, :x.shape[2]-1, :x.shape[3]-1] - x[:, :, :x.shape[2]-1, 1:x.shape[3]]\n",
    "        )\n",
    "        loss = torch.sum(torch.pow(a+b, 1.25))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405b05a",
   "metadata": {},
   "source": [
    "数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faeabb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms as tfs\n",
    "\n",
    "\n",
    "def get_crop_size(crop_size, upscale=2):\n",
    "    return crop_size - (crop_size % upscale)\n",
    "\n",
    "\n",
    "def input_transform(img, idx, boxes, crop_size, upscale_factor=2):\n",
    "    x1, y1, w, h = list(map(int, boxes[idx].strip().split()[1:]))\n",
    "    img = img.crop([x1, y1, x1+w, y1+h])\n",
    "    return tfs.Compose([\n",
    "        tfs.CenterCrop(crop_size),\n",
    "        tfs.Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC)\n",
    "    ])(img)\n",
    "\n",
    "\n",
    "def target_transform(img, idx, boxes, crop_size):\n",
    "    x1, y1, w, h = list(map(int, boxes[idx].strip().split()[1:]))\n",
    "    img = img.crop([x1, y1, x1 + w, y1 + h])\n",
    "    return tfs.Compose([\n",
    "        tfs.CenterCrop(crop_size)\n",
    "    ])(img)\n",
    "\n",
    "\n",
    "def generate_data(row_path, save_path, file_path, upscale_factor=4, divide=0.95):\n",
    "    all_data = os.listdir(row_path)\n",
    "    data_length = 30000\n",
    "    train_stop = int(data_length * divide)\n",
    "    crop_size = get_crop_size(128, upscale_factor)\n",
    "    f = open(file_path)\n",
    "    boxes = f.readlines()[2:]\n",
    "    if not os.path.exists(os.path.join(save_path, \"train\")):\n",
    "        os.makedirs(os.path.join(save_path, \"train\"))\n",
    "    f_train = open(os.path.join(save_path, \"train.txt\"), \"w\")\n",
    "    if not os.path.exists(os.path.join(save_path, \"val\")):\n",
    "        os.makedirs(os.path.join(save_path, \"val\"))\n",
    "    f_val = open(os.path.join(save_path, \"val.txt\"), \"w\")\n",
    "    for t in range(0, train_stop):\n",
    "        img = Image.open(os.path.join(row_path, all_data[t].strip()))\n",
    "        label = img.copy()\n",
    "        img = input_transform(img, t, boxes, crop_size, upscale_factor)\n",
    "        label = target_transform(label, t, boxes, crop_size)\n",
    "        if not os.path.exists(os.path.join(save_path, \"train\", \"img\")):\n",
    "            os.makedirs(os.path.join(save_path, \"train\", \"img\"))\n",
    "        img.save(os.path.join(save_path, \"train\", \"img\", \"{}.jpg\".format(t)))\n",
    "        if not os.path.exists(os.path.join(save_path, \"train\", \"label\")):\n",
    "            os.makedirs(os.path.join(save_path, \"train\", \"label\"))\n",
    "        label.save(os.path.join(save_path, \"train\", \"label\", \"{}.jpg\".format(t)))\n",
    "        f_train.write(f\"{t}.jpg\\n\")\n",
    "        f_train.flush()\n",
    "\n",
    "    for v in range(train_stop, data_length):\n",
    "        img = Image.open(os.path.join(row_path, all_data[v].strip()))\n",
    "        label = img.copy()\n",
    "        img = input_transform(img, v, boxes, crop_size, upscale_factor)\n",
    "        label = target_transform(label, v, boxes, crop_size)\n",
    "        if not os.path.exists(os.path.join(save_path, \"val\", \"img\")):\n",
    "            os.makedirs(os.path.join(save_path, \"val\", \"img\"))\n",
    "        img.save(os.path.join(save_path, \"val\", \"img\", \"{}.jpg\".format(v - train_stop)))\n",
    "        if not os.path.exists(os.path.join(save_path, \"val\", \"label\")):\n",
    "            os.makedirs(os.path.join(save_path, \"val\", \"label\"))\n",
    "        label.save(os.path.join(save_path, \"val\", \"label\", \"{}.jpg\".format(v - train_stop)))\n",
    "        f_val.write(f\"{v - train_stop}.jpg\\n\")\n",
    "        f_val.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1300b2f",
   "metadata": {},
   "source": [
    "自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59727ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as tfs\n",
    "\n",
    "\n",
    "class SRGANDataset(Dataset):\n",
    "    def __init__(self, data_path, ty=\"train\"):\n",
    "        self.dataset = []\n",
    "        self.path = data_path\n",
    "        self.ty = ty\n",
    "        f = open(os.path.join(data_path, \"{}.txt\".format(ty)))\n",
    "        self.dataset.extend(f.readlines())\n",
    "        f.close()\n",
    "        self.tfs = tfs.Compose([\n",
    "            tfs.ToTensor(),\n",
    "            tfs.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.dataset[index].strip()\n",
    "        img = Image.open(os.path.join(self.path, self.ty, \"img\", img_name))\n",
    "        label = Image.open(os.path.join(self.path, self.ty, \"label\", img_name))\n",
    "        img = self.tfs(img)\n",
    "        label = self.tfs(label)\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf7e274",
   "metadata": {},
   "source": [
    "网络训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceab099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dataset\n",
    "import os\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "import models\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import loss\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    record = {\"train_loss_d\": [], \"train_loss_g\": [], \"train_psnr\": [], \"val_loss\": [], \"val_psnr\": []}\n",
    "    x_epoch = []\n",
    "\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.device = self.args.device\n",
    "        self.gnet = models.Generator()\n",
    "        self.dnet = models.Discriminator()\n",
    "        batch = self.args.batch\n",
    "        self.train_loader = DataLoader(dataset.SRGANDataset(self.args.data_path, \"train\"),\n",
    "                                       batch_size=batch, shuffle=True, drop_last=True)\n",
    "        self.val_loader = DataLoader(dataset.SRGANDataset(self.args.data_path, \"val\"),\n",
    "                                     batch_size=batch, shuffle=False, drop_last=True)\n",
    "        self.criterion_g = loss.PerceptualLoss(self.device)\n",
    "        self.regularization = loss.RegularizationLoss()\n",
    "        self.criterion_d = torch.nn.BCELoss()\n",
    "        self.epoch = 0\n",
    "        self.lr = 1e-3\n",
    "        self.best_psnr = 0.\n",
    "        if self.args.resume:\n",
    "            if not os.path.exists(self.args.save_path):\n",
    "                print(\"No params, start training...\")\n",
    "            else:\n",
    "                param_dict = torch.load(self.args.save_path)\n",
    "                self.epoch = param_dict[\"epoch\"]\n",
    "                self.lr = param_dict[\"lr\"]\n",
    "                self.dnet.load_state_dict(param_dict[\"dnet_dict\"])\n",
    "                self.gnet.load_state_dict(param_dict[\"gnet_dict\"])\n",
    "                self.best_psnr = param_dict[\"best_psnr\"]\n",
    "                print(\"Loaded params from {}\\n[Epoch]: {}   [lr]: {}    [best_psnr]: {}\".format(self.args.save_path,\n",
    "                                                                                                self.epoch, self.lr,\n",
    "                                                                                                self.best_psnr))\n",
    "        self.dnet.to(self.device)\n",
    "        self.gnet.to(self.device)\n",
    "        self.optimizer_d = torch.optim.Adam(self.dnet.parameters(), lr=self.lr)\n",
    "        self.optimizer_g = torch.optim.Adam(self.gnet.parameters(), lr=self.lr*0.1)\n",
    "        self.real_label = torch.ones([batch, 1, 1, 1]).to(self.device)\n",
    "        self.fake_label = torch.zeros([batch, 1, 1, 1]).to(self.device)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_psnr(img1, img2):\n",
    "        return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.dnet.train()\n",
    "        self.gnet.train()\n",
    "        train_loss_d = 0.\n",
    "        train_loss_g = 0.\n",
    "        train_loss_all_d = 0.\n",
    "        train_loss_all_g = 0.\n",
    "        psnr = 0.\n",
    "        total = 0\n",
    "        start = time.time()\n",
    "        print(\"Start epoch: {}\".format(epoch))\n",
    "        for i, (img, label) in enumerate(self.train_loader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            fake_img = self.gnet(img)\n",
    "            loss_g = self.criterion_g(fake_img, label, self.dnet(fake_img)) + 2e-8*self.regularization(fake_img)\n",
    "            self.optimizer_g.zero_grad()\n",
    "            loss_g.backward()\n",
    "            self.optimizer_g.step()\n",
    "            if i % 2 == 0:\n",
    "                real_out = self.dnet(label)\n",
    "                fake_out = self.dnet(fake_img.detach())\n",
    "                loss_d = self.criterion_d(real_out, self.real_label\n",
    "                                          ) + self.criterion_d(fake_out, self.fake_label)\n",
    "                self.optimizer_d.zero_grad()\n",
    "                loss_d.backward()\n",
    "                self.optimizer_d.step()\n",
    "\n",
    "                train_loss_d += loss_d.item()\n",
    "                train_loss_all_d += loss_d.item()\n",
    "            train_loss_g += loss_g.item()\n",
    "            train_loss_all_g += loss_g.item()\n",
    "            psnr += self.calculate_psnr(fake_img, label).item()\n",
    "            total += 1\n",
    "\n",
    "            if (i+1) % self.args.interval == 0:\n",
    "                end = time.time()\n",
    "                print(\"[Epoch]: {}[Progress: {:.1f}%]time:{:.2f} dnet_loss:{:.5f} gnet_loss:{:.5f} psnr:{:.4f}\".format(\n",
    "                    epoch, (i+1)*100/len(self.train_loader), end-start,\n",
    "                    train_loss_d/self.args.interval,\n",
    "                    train_loss_g/self.args.interval, psnr/total\n",
    "                ))\n",
    "                train_loss_d = 0.\n",
    "                train_loss_g = 0.\n",
    "        print(\"Save params to {}\".format(self.args.save_path1))\n",
    "        param_dict = {\n",
    "            \"epoch\": epoch,\n",
    "            \"lr\": self.lr,\n",
    "            \"best_psnr\": self.best_psnr,\n",
    "            \"dnet_dict\": self.dnet.state_dict(),\n",
    "            \"gnet_dict\": self.gnet.state_dict()\n",
    "        }\n",
    "        torch.save(param_dict, self.args.save_path)\n",
    "        return train_loss_all_d/len(self.train_loader), train_loss_all_g/len(self.train_loader), psnr/total\n",
    "\n",
    "    def val(self, epoch):\n",
    "        self.gnet.eval()\n",
    "        self.dnet.eval()\n",
    "        print(\"Test start...\")\n",
    "        val_loss = 0.\n",
    "        psnr = 0.\n",
    "        total = 0\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            for i, (img, label) in enumerate(self.train_loader):\n",
    "                img = img.to(self.device)\n",
    "                label = label.to(self.device)\n",
    "                fake_img = self.gnet(img).clamp(0.0, 1.0)\n",
    "                loss = self.criterion_g(fake_img, label, self.dnet(fake_img))\n",
    "                val_loss += loss.item()\n",
    "                psnr += self.calculate_psnr(fake_img, label).item()\n",
    "                total += 1\n",
    "\n",
    "            mpsnr = psnr / total\n",
    "            end = time.time()\n",
    "            print(\"Test finished!\")\n",
    "            print(\"[Epoch]: {} time:{:.2f} loss:{:.5f} psnr:{:.4f}\".format(\n",
    "                epoch, end - start, val_loss / len(self.val_loader), mpsnr\n",
    "            ))\n",
    "            if mpsnr > self.best_psnr:\n",
    "                self.best_psnr = mpsnr\n",
    "                print(\"Save params to {}\".format(self.args.save_path))\n",
    "                param_dict = {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"lr\": self.lr,\n",
    "                    \"best_psnr\": self.best_psnr,\n",
    "                    \"gnet_dict\": self.gnet.state_dict(),\n",
    "                    \"dnet_dict\": self.dnet.state_dict()\n",
    "                }\n",
    "                torch.save(param_dict, self.args.save_path1)\n",
    "        return val_loss/len(self.val_loader), mpsnr\n",
    "\n",
    "    def draw_curve(self, fig, epoch, train_loss_d, train_loss_g, train_psnr, val_loss, val_psnr):\n",
    "        ax0 = fig.add_subplot(121, title=\"loss\")\n",
    "        ax1 = fig.add_subplot(122, title=\"psnr\")\n",
    "        self.record[\"train_loss_d\"].append(train_loss_d)\n",
    "        self.record[\"train_loss_g\"].append(train_loss_g)\n",
    "        self.record[\"train_psnr\"].append(train_psnr)\n",
    "        self.record[\"val_loss\"].append(val_loss)\n",
    "        self.record[\"val_psnr\"].append(val_psnr)\n",
    "        self.x_epoch.append(epoch)\n",
    "        ax0.plot(self.x_epoch, self.record[\"train_loss_d\"], \"bo-\", label=\"train_d\")\n",
    "        ax0.plot(self.x_epoch, self.record[\"train_loss_g\"], \"go-\", label=\"train_g\")\n",
    "        ax0.plot(self.x_epoch, self.record[\"val_loss\"], \"ro-\", label=\"val_g\")\n",
    "        ax1.plot(self.x_epoch, self.record[\"train_psnr\"], \"bo-\", label=\"train\")\n",
    "        ax1.plot(self.x_epoch, self.record[\"val_psnr\"], \"ro-\", label=\"val\")\n",
    "        if epoch == 0:\n",
    "            ax0.legend()\n",
    "            ax1.legend()\n",
    "        fig.savefig(r\"./train_fig/train_{}.jpg\".format(epoch))\n",
    "\n",
    "    def lr_update(self):\n",
    "        for param_group in self.optimizer_d.param_groups:\n",
    "            param_group['lr'] = self.lr * 0.1\n",
    "        self.lr = self.optimizer_d.param_groups[0][\"lr\"]\n",
    "        for param_group in self.optimizer_g.param_groups:\n",
    "            param_group['lr'] = self.lr\n",
    "        print(\"===============================================\")\n",
    "        print(\"Learning rate has adjusted to {}\".format(self.lr))\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    t = Trainer(args)\n",
    "    fig = plt.figure()\n",
    "    for epoch in range(t.epoch, t.epoch + args.num_epochs):\n",
    "        train_loss_d, train_loss_g, train_psnr = t.train(epoch)\n",
    "        val_loss, val_psnr = t.val(epoch)\n",
    "        t.draw_curve(fig, epoch, train_loss_d, train_loss_g, train_psnr, val_loss, val_psnr)\n",
    "        # if (epoch + 1) % 10 == 0:\n",
    "        #     t.lr_update()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Training SRGAN with celebA\")\n",
    "    parser.add_argument(\"--device\", default=\"cuda\", type=str)\n",
    "    parser.add_argument(\"--data_path\", default=r\"T:\\srgan\", type=str)\n",
    "    parser.add_argument(\"--resume\", default=False, type=bool)\n",
    "    parser.add_argument(\"--num_epochs\", default=100, type=int)\n",
    "    parser.add_argument(\"--save_path\", default=r\"./weight01.pt\", type=str)\n",
    "    parser.add_argument(\"--save_path1\", default=r\"./weight00.pt\", type=str)\n",
    "    parser.add_argument(\"--interval\", default=20, type=int)\n",
    "    parser.add_argument(\"--batch\", default=8, type=int)\n",
    "    args1 = parser.parse_args()\n",
    "    main(args1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
